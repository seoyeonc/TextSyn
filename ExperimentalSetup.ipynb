{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7206b17e-62ee-4bd0-bc58-ded0ff85eae4",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9520c2e6-ecbf-4cff-8867-b373127300f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5568fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defs\n",
    "def remove_emoji(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "def generate_experiment2(train_size,test_size,added_n,experiments_index):\n",
    "    #---# A: Kaggle \n",
    "    df_train = pd.concat([\n",
    "        df_kaggle[df_kaggle['type'] != 'ENFJ'][::2],\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][train_size:(train_size+added_n)],\n",
    "    ]).reset_index(drop=True)\n",
    "    df_test = pd.concat([\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],\n",
    "        df_kaggle[df_kaggle['type'] != 'ENFJ'][1::2]\n",
    "    ])\n",
    "    df_trains_dct[f'{experiments_index}a'] = df_train \n",
    "    df_tests_dct[f'{experiments_index}a'] = df_test\n",
    "    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n",
    "    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='Kaggle')\n",
    "    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n",
    "    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n",
    "    tidydata1= pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1})).query('type == \"ENFJ\"')\n",
    "    #---# B: GPT\n",
    "    df_train = pd.concat([\n",
    "        df_kaggle[df_kaggle['type'] != 'ENFJ'][::2],\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n",
    "        df_gpt_ENFJ[df_gpt_ENFJ['type'] == 'ENFJ'][:added_n],\n",
    "    ]).reset_index(drop=True)\n",
    "    df_test = pd.concat([\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],\n",
    "        df_kaggle[df_kaggle['type'] != 'ENFJ'][1::2]\n",
    "    ])\n",
    "    df_trains_dct[f'{experiments_index}b'] = df_train \n",
    "    df_tests_dct[f'{experiments_index}b'] = df_test\n",
    "    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n",
    "    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='ChatGPT')\n",
    "    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n",
    "    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n",
    "    tidydata2 = pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1})).query('type==\"ENFJ\"')\n",
    "    #---# C: Kaggle+GPT\n",
    "    df_train = pd.concat([\n",
    "        df_kaggle[df_kaggle['type'] != 'ENFJ'][::2],        \n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n",
    "        df_gpt_ENFJ[df_gpt_ENFJ['type'] == 'ENFJ'][:added_n],\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][train_size:(train_size+added_n)],\n",
    "    ]).reset_index(drop=True)\n",
    "    df_test = pd.concat([\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],\n",
    "        df_kaggle[df_kaggle['type'] != 'ENFJ'][1::2]\n",
    "    ])\n",
    "    df_trains_dct[f'{experiments_index}c'] = df_train \n",
    "    df_tests_dct[f'{experiments_index}c'] = df_test\n",
    "    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n",
    "    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='ChatGPT')\n",
    "    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n",
    "    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n",
    "    tidydata3 = pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1})).query('type==\"ENFJ\"')\n",
    "    #---#\n",
    "    tidydata = pd.concat([tidydata1.assign(Setting = 'Real'),tidydata2.assign(Setting = 'Synthetic'),tidydata2.assign(Setting = 'Real+Synthetic')])\n",
    "    tidydata.to_csv(f\"tidy_csv/tidydata_{experiments_index.replace('/','')}.csv\",index=False)    \n",
    "\n",
    "def generate_experiment3(train_size,test_size,added_n,experiments_index):\n",
    "    #---# A: Kaggle\n",
    "    df_train = pd.concat([\n",
    "        df_kaggle.query('type in [\"ISTP\",\"ESTP\",\"INTP\",\"ISFP\",\"ISTJ\"]')[::2],\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][train_size:(train_size+added_n)],\n",
    "    ]).reset_index(drop=True)\n",
    "    df_test = pd.concat([\n",
    "        df_kaggle.query('type in [\"ISTP\",\"ESTP\",\"INTP\",\"ISFP\",\"ISTJ\"]')[::2],\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],        \n",
    "    ])\n",
    "    df_trains_dct[f'{experiments_index}a'] = df_train \n",
    "    df_tests_dct[f'{experiments_index}a'] = df_test\n",
    "    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n",
    "    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='Kaggle')\n",
    "    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n",
    "    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n",
    "    tidydata1= pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1}))\n",
    "    #---# B: GPT\n",
    "    df_train = pd.concat([\n",
    "        df_kaggle.query('type in [\"ISTP\",\"ESTP\",\"INTP\",\"ISFP\",\"ISTJ\"]')[::2],\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][:train_size],\n",
    "        df_gpt[df_gpt['type'] == 'ENFJ'][:added_n],\n",
    "    ]).reset_index(drop=True)\n",
    "    df_test = pd.concat([\n",
    "        df_kaggle[df_kaggle['type'] == 'ENFJ'][-test_size:],\n",
    "        df_kaggle.query('type in [\"ISTP\",\"ESTP\",\"INTP\",\"ISFP\",\"ISTJ\"]')[::2],\n",
    "    ])\n",
    "    df_trains_dct[f'{experiments_index}b'] = df_train \n",
    "    df_tests_dct[f'{experiments_index}b'] = df_test\n",
    "    _df1 = df_train[:-added_n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n",
    "    _df2 = df_train[-added_n:]['type'].value_counts().reset_index().assign(Source='ChatGPT')\n",
    "    _train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n",
    "    _test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n",
    "    tidydata2 = pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1}))\n",
    "    tidydata = pd.concat([tidydata1.assign(Setting = 'Real'),tidydata2.assign(Setting = 'Synthetic')])\n",
    "    tidydata.to_csv(f\"tidy_csv/tidydata_{experiments_index.replace('/','')}.csv\",index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847aa835-a38d-427a-bac3-b98d24d24ed0",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5661086-a6f2-4da8-90ae-e9498dee05e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = pd.read_csv(\"data/df_kaggle.csv\")\n",
    "df_gpt = pd.read_csv(\"data/df_gpt.csv\")\n",
    "df_gpt_ENFJ = df_gpt[df_gpt['type'] == 'ENFJ'][:160] \n",
    "df_gpt_ESTP = df_gpt[df_gpt['type'] == 'ESTP'][:155]\n",
    "df_gpt_ESFP = df_gpt[df_gpt['type'] == 'ESFP'][:176]\n",
    "df_gpt_ESFJ = df_gpt[df_gpt['type'] == 'ESFJ'][:179]\n",
    "df_gpt_ESTJ = df_gpt[df_gpt['type'] == 'ESTJ'][:181]\n",
    "df_trains_dct = dict()\n",
    "df_tests_dct = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf68a3-2c68-43c3-9182-ba84643979dd",
   "metadata": {},
   "source": [
    "### Experiment 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e82384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir tidy_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a260c4ae-e953-4a8d-97ed-3e2c3f042c70",
   "metadata": {},
   "source": [
    "*scenario1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1af141fd-88c0-4c9f-9e3d-4f2e96c81a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_kaggle[::2].reset_index(drop=True)\n",
    "df_test = df_kaggle[1::2].reset_index(drop=True)\n",
    "df_trains_dct['experiment1/scenario1'] = df_train \n",
    "df_tests_dct['experiment1/scenario1'] = df_test \n",
    "_train = df_train['type'].value_counts().reset_index().assign(DataType = 'Train')\n",
    "_test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test')\n",
    "tidydata = pd.concat([_train,_test]).reset_index(drop=True)\n",
    "tidydata.to_csv(\"tidy_csv/tidydata_experiment1scenario1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81143aa6-19d0-41f8-95f0-d25c5ee6235a",
   "metadata": {},
   "source": [
    "*scenario2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af37089e-f53c-4a4a-aafa-fba9da46ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([\n",
    "    df_kaggle[::2],\n",
    "    df_gpt_ESTP,\n",
    "    df_gpt_ESFP,\n",
    "    df_gpt_ESFJ,\n",
    "    df_gpt_ESTJ,\n",
    "]).reset_index(drop=True)\n",
    "df_test = df_kaggle[1::2].reset_index(drop=True)\n",
    "df_trains_dct['experiment1/scenario2'] = df_train \n",
    "df_tests_dct['experiment1/scenario2'] = df_test \n",
    "n = len(df_kaggle[::2])\n",
    "_df1 = df_train[:n]['type'].value_counts().reset_index().assign(Source='Kaggle')\n",
    "_df2 = df_train[n:]['type'].value_counts().reset_index().assign(Source='ChatGpt')\n",
    "_train = pd.concat([_df1,_df2],axis=0).reset_index(drop=True).assign(DataType = 'Train')\n",
    "_test = df_test['type'].value_counts().reset_index().assign(DataType = 'Test',Source='Kaggle')\n",
    "tidydata = pd.concat([_train,_test]).reset_index(drop=True).assign(col = lambda df: df.Source.map({'Kaggle':0,'ChatGPT':1}))\n",
    "tidydata.to_csv(\"tidy_csv/tidydata_experiment1scenario2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685110e-735d-4475-92a4-25baa1d86bbd",
   "metadata": {},
   "source": [
    "### Experiment 2: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30dac3de-57a4-403c-8704-e0f7441f8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_experiment2(train_size=1,test_size=30,added_n=0,experiments_index='experiment2/scenario0')\n",
    "generate_experiment2(train_size=1,test_size=30,added_n=40,experiments_index='experiment2/scenario1')\n",
    "generate_experiment2(train_size=1,test_size=30,added_n=80,experiments_index='experiment2/scenario2')\n",
    "generate_experiment2(train_size=1,test_size=30,added_n=120,experiments_index='experiment2/scenario3')\n",
    "generate_experiment2(train_size=1,test_size=30,added_n=159,experiments_index='experiment2/scenario4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73221be7-2642-4ed3-82c5-bfbcfef7320b",
   "metadata": {},
   "source": [
    "### Experiment 3: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb57d67-41c2-469e-b02e-8f5376ce0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_experiment3(train_size=1,test_size=40,added_n=0,experiments_index='experiment3/scenario0')\n",
    "generate_experiment3(train_size=1,test_size=40,added_n=20,experiments_index='experiment3/scenario1')\n",
    "generate_experiment3(train_size=1,test_size=40,added_n=40,experiments_index='experiment3/scenario2')\n",
    "generate_experiment3(train_size=1,test_size=40,added_n=60,experiments_index='experiment3/scenario3')\n",
    "generate_experiment3(train_size=1,test_size=40,added_n=80,experiments_index='experiment3/scenario4')\n",
    "generate_experiment3(train_size=1,test_size=40,added_n=100,experiments_index='experiment3/scenario5')\n",
    "generate_experiment3(train_size=1,test_size=40,added_n=120,experiments_index='experiment3/scenario6')\n",
    "generate_experiment3(train_size=1,test_size=40,added_n=140,experiments_index='experiment3/scenario7')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e8199-e4c0-4dc3-aabe-6108ca3f9d28",
   "metadata": {},
   "source": [
    "### Save experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ac5f61-7f27-4d5a-b9f3-dbca53fdae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf experiment_setup\n",
    "![ -d \"experiment_setup\" ] || mkdir \"experiment_setup\"\n",
    "with open(file='experiment_setup/df_trains_dct.pickle', mode='wb') as f:\n",
    "    pickle.dump(obj=df_trains_dct,file=f)    \n",
    "with open(file='experiment_setup/df_tests_dct.pickle', mode='wb') as f:\n",
    "    pickle.dump(obj=df_tests_dct,file=f)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
